{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /Users/marcus/anaconda3/lib/python3.11/site-packages (0.12.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/marcus/anaconda3/lib/python3.11/site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/marcus/anaconda3/lib/python3.11/site-packages (from imbalanced-learn) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Users/marcus/anaconda3/lib/python3.11/site-packages (from imbalanced-learn) (1.4.1.post1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/marcus/anaconda3/lib/python3.11/site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/marcus/anaconda3/lib/python3.11/site-packages (from imbalanced-learn) (3.3.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/marcus/anaconda3/lib/python3.11/site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: imbalanced-learn in /Users/marcus/anaconda3/lib/python3.11/site-packages (0.12.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in /Users/marcus/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/marcus/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/marcus/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/marcus/anaconda3/lib/python3.11/site-packages (from scikit-learn) (3.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade imbalanced-learn\n",
    "# !pip install --upgrade scikit-learn\n",
    "!pip install --upgrade scikit-learn imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "Failed to import duecredit due to No module named 'duecredit'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from causalml.inference.meta import BaseXClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(r'/Users/marcus/Documents/ae hackathon/dataset/65d4f0fcb8af9_amex_campus_challenge_train_3.csv')\n",
    "eval_set = pd.read_csv('/Users/marcus/Documents/ae hackathon/dataset/65d4b8b2ebfe9_amex_campus_challenge_eval_round1_2.csv' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "must_keep_train_cols = [\"ind_recommended\",\"activation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move 'distance_05' column to the first position for train_set_recommended\n",
    "if('distance_05' in train_set.columns):\n",
    "    col = train_set.pop('distance_05')\n",
    "    train_set.insert(0, col.name, col)\n",
    "\n",
    "train_set_recommended = train_set[train_set['ind_recommended'] == 1].drop(columns=['customer', 'merchant'],axis=1,inplace=False)\n",
    "train_set_not_recommended = train_set[train_set['ind_recommended'] == 0].drop(columns=[ 'customer', 'merchant'],axis=1,inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_classes_with_smote(df, class_column, sample_size, seed, k_neighbors=5):\n",
    "    smote = SMOTE(sampling_strategy='auto', k_neighbors=k_neighbors)\n",
    "\n",
    "    # Sample rows where activation is 0 and where activation is 1\n",
    "    filtered_non_activation = df[df[class_column] == 0].sample(n=sample_size, random_state=seed)\n",
    "    filtered_activation = df[df[class_column] == 1]\n",
    "\n",
    "    # Concatenate the filtered dataframes\n",
    "    df_balanced = pd.concat([filtered_non_activation, filtered_activation], axis=0)\n",
    "\n",
    "    # Apply SMOTE to the activation data\n",
    "    X_resampled, y_resampled = smote.fit_resample(df_balanced.drop([class_column], axis=1), df_balanced[class_column])\n",
    "\n",
    "    # Combine the resampled data\n",
    "    df_resampled = pd.DataFrame(X_resampled, columns=df_balanced.drop([class_column], axis=1).columns)\n",
    "    df_resampled[class_column] = y_resampled\n",
    "\n",
    "    return df_resampled\n",
    "\n",
    "def balance_classes(df, class_column, sample_size, seed):\n",
    "    filtered_non_activation = df[df[class_column] == 0].sample(n=sample_size, random_state=seed)\n",
    "    filtered_activation = df[df[class_column] == 1].sample(n=sample_size, random_state=seed)\n",
    "\n",
    "    return pd.concat([filtered_non_activation, filtered_activation], axis=0)\n",
    "\n",
    "\n",
    "# Apply balance_classes_with_smote function to train_set_recommended\n",
    "train_set_recommended = balance_classes_with_smote(train_set_recommended, 'activation', 30000, seed)\n",
    "\n",
    "# Apply balance_classes_with_smote function to train_set_not_recommended\n",
    "train_set_not_recommended = balance_classes(train_set_not_recommended, 'activation', 30000, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_total = pd.concat([train_set_recommended,train_set_not_recommended],axis=0).sample(frac=1,random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uplift Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_learner = BaseXClassifier(outcome_learner=RandomForestClassifier(n_estimators=100,random_state=seed)\n",
    "                            , effect_learner=RandomForestRegressor(n_estimators=100,random_state=seed))\n",
    "\n",
    "x_learner.fit(\n",
    "    train_total.drop(columns=['activation','ind_recommended'],axis=1,inplace=False).values,\n",
    "    treatment=train_total['ind_recommended'].values,\n",
    "    y = train_total['activation'].values \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x_learner.predict(eval_set.fillna(0).drop(columns=['merchant', 'customer'],axis=1,inplace=False).values)\n",
    "submission = eval_set[[\"customer\",\"merchant\"]].assign(predicted_score=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
